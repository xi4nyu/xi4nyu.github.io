---
title: AI 系列:从 0 开始
tags:
  - AI
categories: AI
date: 2025-03-01 17:31:01
---

### 开篇

自从2022年底的`ChatGPT`发布后，大家发现`ChatGPT`是有始以来最快突破一亿用户的应用，用时仅仅2个月。2025春节期间的`deepseek`出圈，又带来了新的热潮，这一波AI浪潮的来临，间接的影响着行业和每一个人，做为软件开发人员我们也要积极的拥抱。首先我计划从一些学习资料开始学起，看看大家是如何进行学习的。我参考了极客时间的郑晔老师的<<程序员的 AI 开发第一课>>，之所以选择这节课做为开始，是因为我学习过郑老师的<<10x程序员工作法>>很受启发，还有一点就是和郑老师的背景类似，都是偏向后端技术的程序员，有相似的经历。

`ChatGPT`是以聊天的形式呈现，背后支撑的是`GPT`模型，它是大语言模型里最有代表性的一个。

  `LLM`三个特点:
  - 它是模型，是AI的核心。
  - 它是语言模型，其核心能力在于语言能力。
  - 它是大语言模型，与传统的模型相比，它最大的特点就是“大”。

  `GPT`模型可以做什么？
  - 知识丰富：拥有海量的知识，可以回答各种类型的问题。
  - 个性化：可以根据上下文理解人们的意图，提供个性化的回答。
  - 自我改进：能够在对话中不断的改进，在将来的对话中避免类似错误。
  - 知法守法：会遵守道德和法律规范。

### 技术角度理解大模型

站在技术角度理解大模型，就是搞懂大模型到底做了些什么。其实大模型的工作简单，一次添加一个词。借助<<这就是ChatGPT>>里的一个例子来看一下：

  - 假如我手里的文本是"The best thing about AI is its ability to"(AI最棒的地方在于它能)。`GPT`做的事情就是列出随后可能出现的词及其出现的“概率”，有了这个带有概率词的列表，我们就会从这些词中选择一个词。把它附加到我们的文本上，再次询问大模型下一个词是什么。然后就是不断的重复这个过程。

  - 在这里要引入一个词就是`Token`，它是我们理解大模型的第一个重要的概念。`Token`可能是一个单词组合，甚至可能是单词的一部分。大模型厂商就是根据`Token`来收费的。

**随机性**
温度(`Temperature`)另一个重要的概念，如果大模型生成的内容都是千篇一率，那就没有任何的创造性。引入随机性让文章更有“创造力“。

**字符串转向量**
我们要将信息交给大模型处理，首先需要将输入转成向量。为什么呢？因为大模型除了处理字符串，还要处理图片，视屏，音频等，只要把这些输入转成向量，AI算法都可以轻松地处理了。

1. 怎么把字符串变成向量呢？

- 第一步：`One-Hot` 编码
- 第二步：把编码进行压缩

`One-Hot`编码就是将离散的分类转换成二进制向量。下面这个表格中，红绿蓝在向量里各占一位，有值是1，没有为0，红对应：[1,0,0]，当我们输入“红绿红蓝“，就会得到对应的四个向量：[1,0,0]、[0,1,0]、[1,0,0]、[0,0,1]，这就是最简单的One-Hot编码。

||w_红|w_绿|w_蓝|w_编码|
| --- | --- | --- | --- | --- |
|红| 1 | 0 | 0 | [1,0,0]|
|绿| 0 | 1 | 0 | [0,1,0]|
|蓝| 0 | 0 | 1 | [0,0,1]|

如果字符特别多，那么一个量中就有大量的0的存在，真正有含义的位并不多。所以我们会进行下一个处理过程，对编码以进行压缩，得到我们想要的`Embedding`。

### 用好大模型

要想用好`GPT`，需要做到以下几点:
- 定义任务目标。
- 给`GPT`下达命令。
- 根据生成的结果进行调整。
明确目标后，我们就可以给`GPT`下达命令了，这里的“命令”就是提示词。

**怎么写好提示词**
站在用户的角度，写好提示词只需要掌握一个提示词公式即可：

    提示词 = 定义角色 + 背景信息 + 任务目标 + 输出要求

- 定义角色的作用是为`GPT`赋予特定的角色，让`GPT`从特定的角度进行思考和回答。
- 背景信息指的是为`GPT`提供与任务相关的背景知识，包括但不限于相关概念、事件、人物等。这些背景信息有助于`GPT`更好地理解任务，并产生正确的内容和回答提供支持。
- 任务目标和输出要求，是我们向`GPT`提出的要求。

### 提示工程

仅仅掌握上面的这个公式对于开发一个大模型应用而言是不够的。为了开发大模型应用，我们需要进一步扩展自己对于提示词的理解，掌握更多关于提示词的知识，这就是--提示工程。

提示工程就是研究怎么写提示词，之所以有提示工程，很重要的原因就是大模型在不同人眼中做的事情差异很大。在我们开发人员眼中，我们需要**大模型处理复杂任务场景的能力**。

- 零样本提示（`Zero-Shot Prompting`）

大模型的一个特点是知识丰富，所以大模型本身是知道很多东西的。这个情况下，所以我们不需要给大模型过多的提示，这种提示词的写法称为零样本提示。

- 少样本提示（`Few-Shot Prompting`）
虽然大模型知识丰富，但它并不是无所不知的，尤其是它对我们要完成的工程是一无所知的。这时我们只要给它一些例子，帮助它理解我们的工作内容，它就会很好地进行推理。

- 思维链提示（`Chain-of-Thought Prompting`）
大模型是一个语言模型，它的特长在语言能力上，它在数学推理等存在不足，我们经常看到大模型在一些简单的数学问题上闹笑话。为了让大模型更好的完成工作，我们需要让它慢下来，不要用直觉回答问题。思维链有少样本，也有零样本，只要在提示词里添加 "Let's think step by step" 就行。

- `ReAct` 框架
上面这些提示技术都是大模型自身的推理过程，不过很多人对大模型的预期可不仅仅局限于“文字游戏”。如果让大模型和周边做更多结合是不是可以做更多的事情了呢？`ReAct`框架就是这样诞生的。它是`Reasoning`+`Acting`两个单词，推理+行动的缩写。

关于提示工程更多的内容可以参考: [提示工程指南](https://www.promptingguide.ai/zh)。